{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuraliKrishnadata/google_colab_working_files/blob/main/Arima_Assinment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPlrSz4t78eN"
      },
      "source": [
        "# Simple ARIMA model for non-seasonal time-serie forecast\n",
        "\n",
        "Our goal in this challenge is to apply the basic concepts of time series analysis on one-dimension data\n",
        "\n",
        "In this challenge, we'll go through the following steps :\n",
        "1. load and visualize the data;\n",
        "2. train our models and make predictions;"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ngRJxcmV9n8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a50pkuYW78eO"
      },
      "source": [
        "##  1. Load Data\n",
        "Let's start by loading the time series of this real use case: Daily sales of a restaurant"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"/content/drive/MyDrive/Machine_Learing_files/AI_ML_for_Time_series_forcasting/Re_ [IMPORTANT] Se패ances Times Series Forecasting Promo DSBA EDC Mars 2025.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn0BW4H683tv",
        "outputId": "3276fcbe-80b9-485c-d735-bd591599319f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/drive/MyDrive/Machine_Learing_files/AI_ML_for_Time_series_forcasting/Re_ [IMPORTANT] Se패ances Times Series Forecasting Promo DSBA EDC Mars 2025.zip, /content/drive/MyDrive/Machine_Learing_files/AI_ML_for_Time_series_forcasting/Re_ [IMPORTANT] Se패ances Times Series Forecasting Promo DSBA EDC Mars 2025.zip.zip or /content/drive/MyDrive/Machine_Learing_files/AI_ML_for_Time_series_forcasting/Re_ [IMPORTANT] Se패ances Times Series Forecasting Promo DSBA EDC Mars 2025.zip.ZIP.\n",
            "\n",
            "No zipfiles found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "AGgs1qJE84ik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52cded1b-834e-4b7a-d225-78deb0cf8a16"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "scrolled": false,
        "id": "xNgsL9wH78eP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "b2b5dfd6-f980-440a-dd90-6c4f577a3a1a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Daily_restaurant_sales.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2531697269.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Reading the data from souce to pandas dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresturant_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Daily_restaurant_sales.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Daily_restaurant_sales.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Reading the data from souce to pandas dataframe\n",
        "resturant_data = pd.read_csv('/content/Daily_restaurant_sales.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resturant_data.sample(10)"
      ],
      "metadata": {
        "id": "dPozdVs09g0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resturant_data.shape"
      ],
      "metadata": {
        "id": "aw0I8BB6brej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bP37nLfd78eP"
      },
      "source": [
        "This abstract time serie does not seem seasonal, but with some increasing trend and somehow \"sticky\" (i.e. with some auto-regressivity). So it may be a good candidate for Auto-Regresive Moving Average (ARIMA) models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RztrNu5a78eP"
      },
      "source": [
        "## 2. Build ARIMA model\n",
        "We will try to forecast the data thanks to ARIMA models (Auto Regressive Integrated Moving Average).\n",
        "\n",
        "For that, we will need to :\n",
        "1. find how to stationarize the time serie (I in SARIMA)\n",
        "2. find the auto-regressive (AR) part\n",
        "3. find the Moving-Average (MA) part\n",
        "4. Fit\n",
        "5. Assess performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjIg29HD78eQ"
      },
      "source": [
        "### Step 1 - Ensure stationarity\n",
        "\n",
        "ARIMA models applies to \"stationary\" time series only.\n",
        "\n",
        "游녤 Check its stationarity precisely using the [`Augmented Dick Fuller test`](https://www.statsmodels.org/stable/generated/statsmodels.tsa.stattools.adfuller.html), and especially its p-value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmOnaFm578eQ"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# Perform the Augmented Dickey-Fuller test\n",
        "result = adfuller(resturant_data['x'])\n",
        "\n",
        "# Print the results\n",
        "print('ADF Statistic: %f' % result[0])\n",
        "print('p-value: %f' % result[1])\n",
        "print('Critical Values:')\n",
        "for key, value in result[4].items():\n",
        "    print('\\t%s: %.3f' % (key, value))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7f2q4oK78eQ"
      },
      "source": [
        "The p-value should be  less than 0.05 to have a 95% confidence in the stationarity.  \n",
        "If the p-value is larger than 0.05, we cannot reject the null hypothesis (null hypothesis = \"the process is not stationary\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MsSWTyP78eQ"
      },
      "source": [
        "If the time series is not stationary, it needs to be stationarized through **differencing**.\n",
        "- It means that we take the difference between each value and the preceding one (*first difference*).\n",
        "- Repeat process on the differentiated serie if you want the *second difference*, etc...\n",
        "\n",
        "游녤 Find the minimum order of differencing we need to make it stationnary (plot the curves to visualize them, and print their adfuller p-value to be sure)\n",
        "\n",
        "<details>\n",
        "    <summary>Hint</summary>\n",
        "\n",
        "`pd.Series.diff`\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LuU3I1qs78eR"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate the first difference\n",
        "resturant_data_diff_1 = resturant_data['x'].diff().dropna()\n",
        "\n",
        "# Calculate the second difference\n",
        "resturant_data_diff_2 = resturant_data_diff_1.diff().dropna()\n",
        "\n",
        "# Plot the original and differenced series\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(resturant_data['x'], label='Original')\n",
        "plt.plot(resturant_data_diff_1, label='First Difference')\n",
        "plt.plot(resturant_data_diff_2, label='Second Difference')\n",
        "plt.legend()\n",
        "plt.title('Original and Differenced Time Series')\n",
        "plt.show()\n",
        "\n",
        "# Perform ADF test on the first difference\n",
        "result_diff_1 = adfuller(resturant_data_diff_1)\n",
        "print('ADF Statistic (First Difference): %f' % result_diff_1[0])\n",
        "print('p-value (First Difference): %f' % result_diff_1[1])\n",
        "\n",
        "# Perform ADF test on the second difference\n",
        "result_diff_2 = adfuller(resturant_data_diff_2)\n",
        "print('ADF Statistic (Second Difference): %f' % result_diff_2[0])\n",
        "print('p-value (Second Difference): %f' % result_diff_2[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT8N3dV978eR"
      },
      "source": [
        "We have a close-call here between one and two diff orders. Differentiating too much a time series may also reduce performance of your ARIMA models. Let's have a closer look:\n",
        "\n",
        "游녤 Plot autocorrelation plot ([`plot_acf`](https://www.statsmodels.org/stable/generated/statsmodels.graphics.tsaplots.plot_acf.html)) for diff order 1 and 2.\n",
        "\n",
        "(游눠Pro tip: Avoid duplicating statsmodels plots by calling `plt.show()` or by adding `;` to the end of each instantiation of a statsmodels plot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "QjsGTtvQ78eR"
      },
      "outputs": [],
      "source": [
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "\n",
        "#First Auto correlation\n",
        "resturant_data_diff_1 = resturant_data['x'].diff().dropna()\n",
        "plt.figure(figsize=(12, 20))\n",
        "plot_acf(resturant_data_diff_1, lags=40)\n",
        "plt.title('Autocorrelation Plot (First Difference)')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyTuNk5A78eR"
      },
      "source": [
        "In our \"second order diff\" autocorrelation plot, the lag coefficient n춿1 is close to 0, while the second one escapes far into negative territory. This might indicate we have over-differentiated the series. (Remember: we never care about the lag n춿0 which is always equal to 1)\n",
        "\n",
        "游녤 Let's (temptatively) keep only one diff order and name this series `y_diff` (we can always try more diff later)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJuXLmH178eR"
      },
      "outputs": [],
      "source": [
        "#Second order defference\n",
        "resturant_data_diff_2 = resturant_data_diff_1.diff().dropna()\n",
        "plt.figure(figsize=(12, 6))\n",
        "plot_acf(resturant_data_diff_2, lags=40)\n",
        "plt.title('Autocorrelation Plot (Second Difference)') # Changed title for clarity\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofXSwyYi78eR"
      },
      "source": [
        "We just found the term \"I\" in ARIMA: `d = 1` for 1-diff before stationary (I refers to \"integration\", \"d\" for differentiation...)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHP0Vuip78eR"
      },
      "source": [
        "### Step 2 - Select AR order (p) and MA order (q)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-j6zDNIs78eR"
      },
      "source": [
        "#### MA($\\color{blue}{q}$) = number of lag beyond which the $\\color{blue}{ACF}$ of  $Y^{\\color{green}{(d)}}$ cuts off"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXCwzWWf78eR"
      },
      "source": [
        "MA order (`q`) can be found by looking at the autocorrelation plot ([`plot_acf`](https://www.statsmodels.org/stable/generated/statsmodels.graphics.tsaplots.plot_acf.html)) applied to`y_diff`.\n",
        "\n",
        "游녤 determine `q`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTEp2_Mb78eR"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Assuming y_diff is the first difference of the data\n",
        "# If y_diff is not defined, use resturant_data['x'].diff().dropna()\n",
        "y_diff = resturant_data['x'].diff().dropna()\n",
        "\n",
        "\n",
        "# Plot the ACF of y_diff\n",
        "plot_acf(y_diff, lags=20)\n",
        "plt.title('Autocorrelation Plot (y_diff)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTbwyMfP78eR"
      },
      "source": [
        "We could choose q = 4, but it's more conservatively to try with `q=2` to start with.\n",
        "\n",
        "When in doubt, go with the simpler model that sufficiently explains the Y."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFiCcooy78eR"
      },
      "source": [
        "#### AR($\\color{red}{p}$) = number of lags beyond which the $\\color{red}{PACF}$ of $Y^{\\color{green}{(d)}}$  cuts off"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xcYT1p678eR"
      },
      "source": [
        "AR order (`p`) can be found by investigating the **p**artial autocorrelation plot [`plot_pacf`](https://www.statsmodels.org/stable/generated/statsmodels.graphics.tsaplots.plot_pacf.html) applied to `y_diff`.\n",
        "\n",
        "(Partial autocorrelation can be imagined as the correlation between the series and its lag, after excluding the contributions from the intermediate lags. So, PACF sort of conveys the pure correlation between a lag and the series)\n",
        "\n",
        "游녤 Determine `p`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPep-KTD78eS"
      },
      "outputs": [],
      "source": [
        "from statsmodels.graphics.tsaplots import plot_pacf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming y_diff is the first difference of the data\n",
        "# If y_diff is not defined, use resturant_data['x'].diff().dropna()\n",
        "y_diff = resturant_data['x'].diff().dropna()\n",
        "\n",
        "# Plot the PACF of y_diff\n",
        "plot_pacf(y_diff, lags=20)\n",
        "plt.title('Partial Autocorrelation Plot (y_diff)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxRw3ySb78eS"
      },
      "source": [
        "We could choose `p = 3` as the first 3 lag terms seems above the significance level, but we could also go with a simpler model `p = 1`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thB3gvFz78eS"
      },
      "source": [
        "### Step 3 - Build the model\n",
        "\n",
        "Now that you have chosen the values for `p`, ` d` and `q` for the ARIMA,\n",
        "\n",
        "游녤 build the `arima_model` from `statsmodels`.\n",
        "- fit the the model\n",
        "- print the model (`.summary`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "CiMP8HrN78eS"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "arm_model=ARIMA(resturant_data['x'],order=(1,1,2))\n",
        "model_fit=arm_model.fit()\n",
        "print(model_fit.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPu00If378eS"
      },
      "source": [
        "驕뢢잺 If your p-values are too high, try remove these terms by reducing the corresponding AR or SA coefficients.\n",
        "\n",
        "You can evaluate overall performance of your fit by minimizing the [`AIC - akaike information criterion`](https://towardsdatascience.com/the-akaike-information-criterion-c20c8fd832f2) value\n",
        "\n",
        "It seems that the (1,1,1) ARIMA models have less chance of overfitting (p-values remains low) and maintain a quasi similar AIC score than other models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CZIuLf478eS"
      },
      "source": [
        "## 3. Evaluate model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9oJc8_c78eS"
      },
      "source": [
        "游녤 Visualize your model predictions with `.plot_predict()`\n",
        "\n",
        "- Look closely at the method default params, especially `dynamic`.\n",
        "- Do you think your model would have such good performance in reality?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPVgXyCF78eS"
      },
      "outputs": [],
      "source": [
        "# Make predictions using the fitted model\n",
        "predictions = model_fit.predict(start=0, end=len(resturant_data['x']) - 1, dynamic=False)\n",
        "\n",
        "# Plot the original data and the predictions\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(resturant_data['x'], label='Original')\n",
        "plt.plot(predictions, label='Predictions (dynamic=False)')\n",
        "plt.title('ARIMA Model Predictions (dynamic=False)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCIYkTK078eS"
      },
      "source": [
        "驕뢢잺 `dynamic=False` actually makes use of all available values `y` in order to predict `y_pred`, making your ARIMA prediction use up to $y_{t-1}$ to predict $y_t$. In reality, you don't have access to all `y`, especially if you want to predict several intervals in the future.\n",
        "\n",
        "游녤 Try to use `dynamic=True` to plot a prection of the _last 15 values_ in a situation where the model only have _access to data up to 85_. That is to say, the model:\n",
        "- predicts 86 based on true [1...85]\n",
        "- then predicts 87 based on [1...85] _plus_ it's previouly predicted value for 86\n",
        "- etc...iteratively until 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhVUGG_q78eS"
      },
      "outputs": [],
      "source": [
        "# Make predictions with dynamic=True for the last 15 values\n",
        "# The model has access to data up to index 85\n",
        "predictions_dynamic = model_fit.predict(start=85, end=len(resturant_data['x']) - 1, dynamic=True)\n",
        "\n",
        "# Plot the original data and the dynamic predictions\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(resturant_data['x'], label='Original')\n",
        "plt.plot(predictions_dynamic, label='Predictions (dynamic=True)')\n",
        "plt.title('ARIMA Model Predictions (dynamic=True)')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aemJrLrT78eS"
      },
      "source": [
        "驕뢢잺 That's still not a _true_ forecast!! Why??\n",
        "\n",
        "<details>\n",
        "    <summary>Answer</summary>\n",
        "\n",
        "Our model has \"seen\" the whole `y_true` serie during the fitting phase!\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TfK0n6A78eS"
      },
      "source": [
        "### 3.1 Out-of-sample forecasts (real \"future\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zySx1b1G78eS"
      },
      "source": [
        "游녤 Create a train-test-split keep the last 15 datapoints only for the test set, and train your ARIMA on the train set only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nK9mlL6878eS"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train, test = train_test_split(resturant_data, test_size=15, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djyonHRv78eS"
      },
      "source": [
        "游녤 We are \"now\" in step 85 and have never seen the future:\n",
        "- Use `.forecast()` method on your fitted model to \"forecast\" the 15 next datapoints (i.e beyond the end of your train dataset)\n",
        "- Plot forecasted values as well as the higher and lower range of 95% uncertainty interval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaNs4DlY78eS"
      },
      "outputs": [],
      "source": [
        "forcast=model_fit.forecast(steps=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFgbwnm778eS"
      },
      "outputs": [],
      "source": [
        "# Get the forecast with confidence intervals\n",
        "forecast_result = model_fit.get_forecast(steps=15)\n",
        "forecast_mean = forecast_result.predicted_mean\n",
        "conf_int = forecast_result.conf_int(alpha=0.05) # 95% confidence interval\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(resturant_data['x'][:85], label='Original (Train)') # Plot training data\n",
        "plt.plot(resturant_data['x'][85:], label='Original (Test)') # Plot test data\n",
        "plt.plot(forecast_mean, label='Forecasted')\n",
        "plt.fill_between(conf_int.index, conf_int.iloc[:, 0], conf_int.iloc[:, 1], color='k', alpha=0.1, label='95% Confidence Interval')\n",
        "\n",
        "plt.title('ARIMA Model Forecast with 95% Confidence Interval')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJ7826_d78eb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVopLV3_78eb"
      },
      "source": [
        "游녤 Try to also plot your previous 85 `y` real datapoints to better grasp model performance relative to the past"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxgIsJMH78eb"
      },
      "outputs": [],
      "source": [
        "# Define y_real and y_pred for plotting\n",
        "y_real = resturant_data['x'][85:] # Test data\n",
        "y_pred = forecast_mean # Forecasted values\n",
        "\n",
        "plt.figure(figsize=(12, 6)) # Increased figure size for better readability\n",
        "plt.plot(range(len(resturant_data)), resturant_data['x'], label='Actual', color='blue')\n",
        "plt.plot(range(85, 85 + len(y_pred)), y_pred, label='Predicted', color='red', linestyle='--') # Adjusted x-axis for predicted values\n",
        "plt.title(\"Model Performance vs Historical Data\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E590fgJZ78eb"
      },
      "source": [
        "### 3.2 Can you trust your 95% confidence interval? (conditions for inference)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xjs-qpVy78eb"
      },
      "source": [
        "游녤 Plot the residuals `model.resid` to ensure there are no patterns\n",
        "- Normally distributed\n",
        "- Mean zero\n",
        "- Uniform variance\n",
        "- No autoregressive patterns (you can plot_acf the residuals if you really want)\n",
        "\n",
        "Note: residuals are constructed by 'seing' all data as in `plot_predict(dynamic=False)`\n",
        "\n",
        "Also try to plot a histogram or kde fit of the residuals to see if they are approximately normally distributed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGXgjSgp78eb"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(model_fit.resid, label='Residuals')\n",
        "plt.title('Residuals Plot')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxTqyjNt78eb"
      },
      "source": [
        "## 3.3 Cross-validated performance metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR9QidzK78eb"
      },
      "source": [
        "游녤 Below are the given the most common performance metrics for time series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i11ykozH78eb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score,mean_squared_error\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da52d0b4"
      },
      "source": [
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_real, y_pred)\n",
        "mae = mean_absolute_error(y_real, y_pred)\n",
        "r2 = r2_score(y_real, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
        "print(f'Mean Absolute Error (MAE): {mae:.2f}')\n",
        "print(f'R-squared (R2): {r2:.2f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ekUC8-h78ec"
      },
      "source": [
        "游녤 Play with you ARIMA hyper-parameters and see the impact on your forecast performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Veo12eCQ78ec"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rafCIg5a78ec"
      },
      "source": [
        "## 4 Grid Search\n",
        "#link to understand Grid Search https://www.lovelyanalytics.com/2017/10/16/grid-search/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IW9JrvKr78ec"
      },
      "source": [
        "Try to run your own gridsearch for (p,d,q) using `pmdarima`. Use at least\n",
        "- `trace=True`\n",
        "- `error_action='ignore'`\n",
        "- `suppress_warnings=True`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXItcwyd78ec"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMl2iCMV78ec"
      },
      "source": [
        "## Cross-validate performance of your model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jl-vvt1R78ec"
      },
      "source": [
        "In practice, Results and GridSearch should always be cross validated:\n",
        "\n",
        "Feel free to use [`sklearn.TimeSeriesSplit`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html) to create continguous K-folds so as to truely evaluate the performance of your model and find the best hyper-params after cross validation\n",
        "\n",
        "<img src='https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_0101.png'>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7py2yg178ec"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "19f98449f5e80f9a8c3374db8836265b262990059173d2a53169726a628cde5d"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}